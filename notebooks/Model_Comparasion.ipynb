!pip install -U transformers datasets evaluate seqeval -q
import numpy as np
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score
from seqeval.metrics import classification_report, accuracy_score as seq_accuracy
from seqeval.metrics import precision_score as seq_precision
from seqeval.metrics import recall_score as seq_recall
from seqeval.metrics import f1_score as seq_f1

from google.colab import drive
drive.mount('/content/drive')

# Copy your project to Google Drive inside "MyDrive"
project_path = "/content/drive/MyDrive/EthioMart-NER-Project"
data_path = "/content/drive/MyDrive/conll_labeled.txt"


from datasets import Dataset
import pandas as pd

def read_conll(file_path):
    tokens = []
    tags = []

    temp_tokens = []
    temp_tags = []

    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if not line:
                if temp_tokens:
                    tokens.append(temp_tokens)
                    tags.append(temp_tags)
                    temp_tokens, temp_tags = [], []
            else:
                parts = line.split()
                if len(parts) >= 2:
                    word = " ".join(parts[:-1])  # Handles phrases like "Addis Ababa"
                    tag = parts[-1]
                    temp_tokens.append(word)
                    temp_tags.append(tag)

    return pd.DataFrame({'tokens': tokens, 'ner_tags': tags})





# Load and convert to HuggingFace Dataset
df = read_conll(data_path)
dataset = Dataset.from_pandas(df)

import numpy as np
from seqeval.metrics import precision_score as seq_precision
from seqeval.metrics import recall_score as seq_recall
from seqeval.metrics import f1_score as seq_f1
from seqeval.metrics import accuracy_score as seq_accuracy

def compute_metrics(pred):
    predictions, labels = pred
    predictions = np.argmax(predictions, axis=2)

    true_labels = [[id_to_label[label] for label in label_seq if label != -100]
                   for label_seq in labels]
    true_preds = [[id_to_label[pred] for pred, label in zip(pred_seq, label_seq) if label != -100]
                  for pred_seq, label_seq in zip(predictions, labels)]

    return {
        "precision": seq_precision(true_labels, true_preds),
        "recall": seq_recall(true_labels, true_preds),
        "f1": seq_f1(true_labels, true_preds),
        "accuracy": seq_accuracy(true_labels, true_preds),
    }
 model_path = "/content/drive/MyDrive/fine_tuned_bert-tiny-amharic"

from transformers import AutoModelForTokenClassification, AutoTokenizer

model = AutoModelForTokenClassification.from_pretrained(model_path)
tokenizer = AutoTokenizer.from_pretrained(model_path)

# Load label mapping directly from the model
id_to_label = model.config.id2label
label_to_id = model.config.label2id
num_labels = model.config.num_labels

def tokenize_and_align_labels(example):
    tokenized_inputs = tokenizer(example["tokens"], truncation=True, is_split_into_words=True)
    labels = []
    word_ids = tokenized_inputs.word_ids()

    previous_word_idx = None
    for word_idx in word_ids:
        if word_idx is None:
            labels.append(-100)
        elif word_idx != previous_word_idx:
            labels.append(label_to_id.get(example["ner_tags"][word_idx], -100))
        else:
            current_label = example["ner_tags"][word_idx]
            if current_label.startswith("B-"):
                current_label = current_label.replace("B-", "I-")
            labels.append(label_to_id.get(current_label, -100))
        previous_word_idx = word_idx

    tokenized_inputs["labels"] = labels
    return tokenized_inputs

tokenized_dataset = dataset.map(tokenize_and_align_labels)
trainer = Trainer(
    model=model,
    args=training_args,
    tokenizer=tokenizer,
    data_collator=data_collator,
    compute_metrics=compute_metrics
)

metrics = trainer.evaluate(eval_dataset=tokenized_dataset)
print(metrics)
